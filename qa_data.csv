Question,Answer
What is the arXiv ID of the text?,arXiv:2501.09223v1
What is the subject classification of the text?,cs.CL
What is the date the text was submitted?,"January 16, 2025"
Who are the authors of the text?,Tong Xiao and Jingbo Zhu
What is the affiliation of the authors?,"NLP Lab, Northeastern University & NiuTrans Research"
What year was the copyright secured?,2021-2025
Under what license is this work distributed?,Creative Commons Attribution-NonCommercial 4.0 Unported License
What is the book's aim?,To outline the basic concepts of large language models and introduce related techniques.
What is the book's focus?,Foundational aspects of large language models.
How many chapters are in the book?,Four
What does Chapter 1 introduce?,The basics of pre-training.
What are common pre-training methods discussed in Chapter 1?,Common pre-training methods and model architectures.
What does Chapter 2 introduce?,"Generative models, which are the large language models we commonly refer to today."
What topics are covered in Chapter 2 regarding generative models?,"Basic process of building these models, scaling up model training, and handling long texts."
What does Chapter 3 introduce?,Prompting methods for large language models.
What prompting strategies are discussed in Chapter 3?,"Various prompting strategies, chain-of-thought reasoning, and automatic prompt design."
What does Chapter 4 introduce?,Alignment methods for large language models.
What is the focus of Chapter 4 regarding alignment?,Instruction fine-tuning and alignment based on human feedback.
What prior knowledge is helpful for reading this book?,"Background in machine learning and natural language processing, and an understanding of neural networks like Transformers."
What if a reader lacks the prior knowledge mentioned?,"It is still perfectly fine, as the content is self-contained."
What is the writing style of the book described as?,A compilation of notes.
What is the notation for a variable?,a
What is the notation for a row vector or matrix?,a
What is the notation for a function of a?,f(a)
What is the notation for the maximum value of f(a)?,max f(a)
What is the notation for the value of a that maximizes f(a)?,arg max<sub>a</sub> f(a)
What is the notation for the input token sequence to a model?,x
What is the notation for the input token at position j?,x<sub>j</sub>
What is the notation for the output token sequence produced by a model?,y
What is the notation for the output token at position i?,y<sub>i</sub>
What is the notation for model parameters?,θ
What is the notation for the probability of a?,Pr(a)
What is the notation for the conditional probability of a given b?,Pr(a|b)
What is the notation for the probability distribution of a variable given b?,Pr(·|b)
What is the notation for the probability of a as parameterized by θ?,Pr<sub>θ</sub>(a)
What is the notation for the hidden state at time step t in sequential models?,h<sub>t</sub>
What is the notation for the matrix of all hidden states over time in a sequence?,H
"What are the notations for query, key, and value matrices in attention mechanisms?","Q, K, V"
What is the notation for the Softmax function?,Softmax(A)
What is the notation for a loss function?,L
What is the notation for a dataset?,D
What is the notation for the gradient of the loss function L with respect to the parameters θ?,∂L/∂θ
What is the notation for KL divergence?,KL(p||q)
When did large language models originate?,From natural language processing.
What is a key insight brought by large language models?,Knowledge of the world and languages can be acquired through large-scale language modeling tasks.
How has this discovery impacted research?,It has profoundly impacted research methodologies in natural language processing and many related disciplines.
What is the new paradigm in NLP research?,"Using large-scale pre-training to obtain foundation models, which are then fine-tuned, aligned, and prompted."
What is a foundation model?,A pre-trained model that can be easily adapted to different tasks.
What are the two types of problems involved in NLP pre-training?,Sequence modeling (or sequence encoding) and sequence generation.
What is the general model definition for sequence modeling and generation?,"o = g(x<sub>0</sub>,x<sub>1</sub>,...,x<sub>m</sub>; θ) = g<sub>θ</sub>(x<sub>0</sub>,x<sub>1</sub>,...,x<sub>m</sub>)"
What are the two fundamental issues in pre-training?,Optimizing θ on a pre-training task and applying the pre-trained model to downstream tasks.
What is unsupervised pre-training?,Optimizing a neural network using a criterion not directly related to specific tasks.
What is supervised pre-training?,Pre-training a neural network on supervised learning tasks.
What is self-supervised pre-training?,Training a neural network using supervision signals generated by itself.
What is a common self-supervised pre-training task?,Predicting a masked word given its preceding or surrounding words.
What are the two major types of models used in NLP pre-training?,Sequence encoding models and sequence generation models.
How are pre-trained sequence encoding models adapted to downstream tasks?,Fine-tuning.
How are pre-trained sequence generation models adapted to downstream tasks?,Fine-tuning or prompting.
What is fine-tuning?,Slightly adjusting the parameters of a pre-trained model using labeled data for a specific downstream task.
What is prompting?,Transforming NLP problems into simple text generation problems by providing instructions or examples to the model.
What is zero-shot learning?,Performing tasks not observed during the training phase.
What is few-shot learning?,Performing tasks using a small number of examples.
What is in-context learning?,Learning from examples provided within the prompt.
What are decoder-only architectures used for?,Developing language models.
What is the standard way to train a decoder-only language model?,Minimizing a loss function over a collection of token sequences.
What loss function is typically used in language modeling?,Log-scale cross-entropy loss.
What is the objective of decoder-only pre-training?,To find the best parameters that minimize the loss on a dataset.
What is the objective of encoder-only pre-training?,To train a model that can generalize across various tasks.
What is masked language modeling?,Masking some tokens in the input sequence and training the model to predict them.
What is a drawback of masked language modeling?,The use of a special token [MASK] that is only used during training.
What is permuted language modeling?,Making sequential predictions of tokens in a permuted order.
What is next sentence prediction (NSP)?,Determining whether two sentences are consecutive in a text.
What is the ELECTRA model?,A model that trains a Transformer encoder to identify whether input tokens are original or altered.
What are encoder-decoder architectures used for?,Modeling sequence-to-sequence problems.
What is a common method for pre-training encoder-decoder models?,Masked language modeling.
What is denoising training?,Training an encoder-decoder model to reconstruct an original sequence from a corrupted input.
What are the different corruption methods used in BART?,"Token masking, token deletion, span masking, sentence reordering, and document rotation."
What are the different pre-training tasks based on the training objectives?,"Language modeling, masked language modeling, permuted language modeling, discriminative training, and denoising autoencoding."
What is BERT?,A Transformer encoder trained using masked language modeling and next sentence prediction.
What is the loss function for BERT?,Loss<sub>BERT</sub> = Loss<sub>MLM</sub> + Loss<sub>NSP</sub>
How are tokens processed in masked language modeling in BERT?,"Token masking (80%), random replacement (10%), and unchanged (10%)."
What is the loss function for masked language modeling in BERT?,Loss<sub>MLM</sub> = -∑<sub>i∈A(x)</sub> log Pr<sub>i</sub>(x<sub>i</sub>|¯x)
What is the loss function for next sentence prediction in BERT?,Loss<sub>NSP</sub> = - log Pr(c<sub>gold</sub>|h<sub>cls</sub>)
What are the components of a BERT input embedding?,"Token embedding, positional embedding, and segment embedding."
What is RoBERTa?,An extension of BERT that uses more training data and removes the NSP loss.
What are some ways to make BERT models more efficient?,"Knowledge distillation, model compression (pruning, quantization), dynamic networks, and parameter sharing."
What is mBERT?,A multi-lingual BERT model trained on data from multiple languages.
What is XLM?,A cross-lingual language model trained on bilingual data.
What is code-switching?,Switching among languages in a text.
How are BERT models applied to downstream tasks?,By integrating them with a prediction network and fine-tuning the combined model.
What are some downstream tasks BERT models are used for?,"Classification (single text, text pairs), regression, sequence labeling, span prediction, and encoding for encoder-decoder models."
What is catastrophic forgetting?,Forgetting previously learned information when updated on new samples.
What are large language models (LLMs)?,Generative models that can understand and generate natural languages.
What is the history of language modeling?,"It dates back to Shannon's experiments in 1951, with n-gram models and neural networks later becoming prominent."
What is the goal of language modeling?,To predict the probability of a sequence of tokens occurring.
What is the chain rule in language modeling?,"Pr(x<sub>0</sub>,...,x<sub>m</sub>) = Π<sup>m</sup><sub>i=0</sub> Pr(x<sub>i</sub>|x<sub>0</sub>,...,x<sub>i-1</sub>)"
How are probabilities estimated in deep learning-based language models?,Using deep neural networks.
What is an auto-regressive decoding process?,Generating a sequence by predicting each token based on previously generated tokens.
What is the architecture of decoder-only LLMs typically based on?,Decoder-only Transformers.
What are the two sub-layers in a Transformer block?,Self-attention sub-layer and FFN sub-layer.
What is the pre-norm architecture?,output = LNorm(F(input)) + input
What is the post-norm architecture?,output = LNorm(F(input) + input)
What is the QKV attention formula?,"Att<sub>qkv</sub>(Q,K,V) = Softmax(QK<sup>T</sup>/√d + Mask)V"
How is the multi-head self-attention function defined?,"F(H) = Merge(head<sub>1</sub>,...,head<sub>τ</sub>)W<sub>head</sub>"
What is the objective of maximum likelihood training for LLMs?,ˆθ = arg max<sub>θ</sub> ∑<sub>x∈D</sub> L<sub>θ</sub>(x)
What are some challenges in training LLMs?,"Large-scale distributed systems, computational resources, and training instability."
How are LLMs fine-tuned?,By maximizing the log-likelihood of the output given the input: ˜θ = arg max<sub>θ</sub> ∑<sub>sample∈Dtune</sub> L<sub>θ</sub>(sample)
What is instruction fine-tuning?,Fine-tuning LLMs on instruction-following data.
What is zero-shot learning in the context of LLMs?,Performing tasks without specific training or fine-tuning.
What is alignment in LLMs?,Guiding LLMs to behave in ways that align with human intentions and values.
What is AI safety?,"Ensuring AI systems are robust, secure, and beneficial."
What are the two alignment steps after pre-training and instruction fine-tuning?,Supervised fine-tuning (SFT) and learning from human feedback.
What is RLHF?,Reinforcement learning from human feedback.
What are the components of RLHF?,"Agent (LLM), reward model, and human feedback."
What are the steps involved in RLHF?,"Train initial policy, collect human feedback, train reward model, fine-tune policy with reinforcement learning."
What is a reward model?,A model that assigns numerical scores to LLM outputs based on human preferences.
How is a reward model trained?,"Using human preference data (pairwise comparisons, ratings, listwise rankings)."
What is the Bradley-Terry model?,A probabilistic model for pairwise comparisons.
What is the Plackett-Luce model?,A probabilistic model for listwise rankings.
What is pointwise reward modeling?,Training a reward model to predict numerical scores for individual outputs.
What is the overoptimization problem?,LLMs overfitting to the reward model and not achieving the true objective.
How can the overoptimization problem be mitigated?,By combining multiple reward models.
What is the advantage of using multiple reward models?,Averaging out biases and errors.
How can we generate preference data automatically?,Using LLMs to generate outputs and label preferences.
What are outcome-based approaches?,Supervising LLMs only on the final result.
What are process-based approaches?,Supervising LLMs on intermediate reasoning steps.
What is Best-of-N sampling?,Selecting the best output from N alternative outputs generated by the LLM using a reward model.
What is rejection sampling?,"Selecting ""best"" outputs and using them to fine-tune the LLM."
What are the main approaches to LLM alignment discussed?,"Supervised fine-tuning (SFT), Reinforcement Learning from Human Feedback (RLHF), and inference-time alignment."
What are the main challenges in LLM alignment?,"Data annotation, computational cost, and the complexity of human values and preferences."
What is the superﬁcial alignment hypothesis?,"Learning primarily occurs during pre-training, ﬁne-tuning contributes little to the underlying knowledge."
What is the weak-to-strong generalization problem?,Using weaker models to improve stronger models.
What is knowledge distillation?,"Training a smaller ""student"" model to mimic a larger ""teacher"" model."
How can smaller models be used to improve larger models?,"Generating synthetic data, adding knowledge distillation loss, data selection/filtering, model ensembling, and model cascading."
What are the challenges in designing high-quality prompts?,"Manual effort, reliance on human expertise, and prompt length."
What is prompt optimization?,Automatically designing and optimizing prompts for LLMs.
What is the prompt optimization framework?,"Prompt search space, performance estimation, and search strategy."
How can LLMs be used in prompt optimization?,"Generating prompts, evaluating prompts, and expanding the prompt search space."
What are soft prompts?,"Hidden, distributed representations of prompts learned within LLMs."
What is an advantage of soft prompts?,They are more efficient and compact than hard prompts.
What is preﬁx ﬁne-tuning?,Appending trainable vectors to the input of each Transformer layer to adapt the model.
What is prompt tuning?,Modifying only the embedding layer to adapt the model.
How can soft prompts be learned with compression?,By learning compressed representations of the context.
What is the goal of prompt length reduction?,To simplify and shorten prompts to reduce computational cost.
How can prompt length be reduced?,"Using heuristics, sequence-to-sequence models, and LLMs for text simplification."
